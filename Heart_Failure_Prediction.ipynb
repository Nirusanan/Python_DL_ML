{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTWddC-SkILo"
      },
      "source": [
        "# Feed forward NN\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beN18NVkk2hl"
      },
      "source": [
        "df = pd.read_csv('/content/heart_failure_clinical_records_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "cacnT1IUFck6",
        "outputId": "2c367320-4b4a-49ee-f6c5-c4bf42bca7c1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  anaemia  creatinine_phosphokinase  ...  smoking  time  DEATH_EVENT\n",
              "0  75.0        0                       582  ...        0     4            1\n",
              "1  55.0        0                      7861  ...        0     6            1\n",
              "2  65.0        0                       146  ...        1     7            1\n",
              "3  50.0        1                       111  ...        0     7            1\n",
              "4  65.0        1                       160  ...        0     8            1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfeaTkTek2Qw",
        "outputId": "ba437978-0501-4e7d-919f-4e91470ab439"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw6SPUX6k2CO"
      },
      "source": [
        "class Dataset(Dataset):\n",
        "    def __init__(self, file):\n",
        "        self.data = pd.read_csv(file)\n",
        "        input_features = self.data.values[:,0:11].astype('float32')\n",
        "        self.x_train = torch.from_numpy(input_features)\n",
        "\n",
        "        target_label = self.data['DEATH_EVENT'].values\n",
        "        self.y_train = torch.from_numpy(target_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.x_train[idx],self.y_train[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ifATo2k1_A"
      },
      "source": [
        "dataset = Dataset('/content/heart_failure_clinical_records_dataset.csv')\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG8AiThGk19D"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.softmax(self.layer1(x))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I6iFM8hk16r"
      },
      "source": [
        "model = Model(11, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkOtJXq5k12_"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRhnxbTvF7yp"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUBrVLrvl6nQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09aee51d-bb93-478d-f332-fba1e0e6b726"
      },
      "source": [
        "epochs = 400\n",
        "\n",
        "for epoch in range(1,epochs+1):\n",
        "    print(\"EPOCH:\",epoch,end=\" \")\n",
        "    running_loss=0\n",
        "    running_acc=0\n",
        "\n",
        "    for data,labels in dataloader:\n",
        "        data,labels=data.to(device),labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output=model.forward(data)\n",
        "        loss=criterion(output,labels)\n",
        "\n",
        "        result=torch.argmax(output,dim=1)\n",
        "        running_loss+=loss.item()\n",
        "        running_acc+=torch.mean((result==labels).type(torch.float))\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    else:\n",
        "        train_loss=running_loss/len(dataloader)\n",
        "        train_acc=running_acc/len(dataloader)\n",
        "\n",
        "        print(\"Training Loss: {:.3f}\".format(train_loss),end=\" \")\n",
        "\n",
        "        print(\"Train Accuracy: {:.2f}%\".format(train_acc.item()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 1 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 2 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 3 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 4 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 5 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 6 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 7 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 8 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 9 Training Loss: 0.629 Train Accuracy: 68.42%\n",
            "EPOCH: 10 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 11 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 12 Training Loss: 0.634 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 67.97%\n",
            "EPOCH: 13 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 14 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 15 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 16 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 17 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 18 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 19 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 20 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 21 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 22 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 23 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 24 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 25 Training Loss: 0.629 Train Accuracy: 68.42%\n",
            "EPOCH: 26 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 27 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 28 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 29 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 30 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 31 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 32 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 33 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 34 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 35 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 36 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 37 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 38 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 39 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 40 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 41 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 42 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 43 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 44 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 45 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 46 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 47 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 48 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 49 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 50 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 51 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 52 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 53 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 54 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 55 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 56 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 57 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 58 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 59 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 60 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 61 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 62 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 63 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 64 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 65 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 66 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 67 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 68 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 69 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 70 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 71 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 72 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 73 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 74 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 75 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 76 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 77 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 78 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 79 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 80 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 81 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 82 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 83 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 84 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 85 Training Loss: 0.641 Train Accuracy: 67.22%\n",
            "EPOCH: 86 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 87 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 88 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 89 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 90 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 91 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 92 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 93 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 94 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 95 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 96 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 97 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 98 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 99 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 100 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 101 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 102 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 103 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 104 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 105 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 106 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 107 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 108 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 109 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 110 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 111 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 112 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 113 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 114 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 115 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 116 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 117 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 118 Training Loss: 0.640 Train Accuracy: 67.37%\n",
            "EPOCH: 119 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 120 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 121 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 122 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 123 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 124 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 125 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 126 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 127 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 128 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 129 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 130 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 131 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 132 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 133 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 134 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 135 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 136 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 137 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 138 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 139 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 140 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 141 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 142 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 143 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 144 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 145 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 146 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 147 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 148 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 149 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 150 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 151 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 152 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 153 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 154 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 155 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 156 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 157 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 158 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 159 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 160 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 161 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 162 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 163 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 164 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 165 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 166 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 167 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 168 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 169 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 170 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 171 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 172 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 173 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 174 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 175 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 176 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 177 Training Loss: 0.629 Train Accuracy: 68.42%\n",
            "EPOCH: 178 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 179 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 180 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 181 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 182 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 183 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 184 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 185 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 186 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 187 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 188 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 189 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 190 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 191 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 192 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 193 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 194 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 195 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 196 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 197 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 198 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 199 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 200 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 201 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 202 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 203 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 204 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 205 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 206 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 207 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 208 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 209 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 210 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 211 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 212 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 213 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 214 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 215 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 216 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 217 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 218 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 219 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 220 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 221 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 222 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 223 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 224 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 225 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 226 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 227 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 228 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 229 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 230 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 231 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 232 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 233 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 234 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 235 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 236 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 237 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 238 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 239 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 240 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 241 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 242 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 243 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 244 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 245 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 246 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 247 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 248 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 249 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 250 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 251 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 252 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 253 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 254 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 255 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 256 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 257 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 258 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 259 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 260 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 261 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 262 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 263 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 264 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 265 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 266 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 267 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 268 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 269 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 270 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 271 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 272 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 273 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 274 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 275 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 276 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 277 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 278 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 279 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 280 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 281 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 282 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 283 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 284 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 285 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 286 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 287 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 288 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 289 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 290 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 291 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 292 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 293 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 294 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 295 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 296 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 297 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 298 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 299 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 300 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 301 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 302 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 303 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 304 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 305 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 306 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 307 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 308 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 309 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 310 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 311 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 312 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 313 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 314 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 315 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 316 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 317 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 318 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 319 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 320 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 321 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 322 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 323 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 324 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 325 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 326 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 327 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 328 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 329 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 330 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 331 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 332 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 333 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 334 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 335 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 336 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 337 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 338 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 339 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 340 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 341 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 342 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 343 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 344 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 345 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 346 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 347 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 348 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 349 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 350 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 351 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 352 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 353 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 354 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 355 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 356 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 357 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 358 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 359 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 360 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 361 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 362 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 363 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 364 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 365 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 366 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 367 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 368 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 369 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 370 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 371 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 372 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 373 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 374 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 375 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 376 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 377 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 378 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 379 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 380 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 381 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 382 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 383 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 384 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 385 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 386 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 387 Training Loss: 0.634 Train Accuracy: 67.97%\n",
            "EPOCH: 388 Training Loss: 0.638 Train Accuracy: 67.52%\n",
            "EPOCH: 389 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 390 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 391 Training Loss: 0.631 Train Accuracy: 68.27%\n",
            "EPOCH: 392 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 393 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 394 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 395 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 396 Training Loss: 0.632 Train Accuracy: 68.12%\n",
            "EPOCH: 397 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 398 Training Loss: 0.637 Train Accuracy: 67.67%\n",
            "EPOCH: 399 Training Loss: 0.635 Train Accuracy: 67.82%\n",
            "EPOCH: 400 Training Loss: 0.632 Train Accuracy: 68.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcKkBEUCwaVt"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4oZhrTdxUr6"
      },
      "source": [
        "test = torch.tensor([[49.0,\t1,\t80,\t0,\t30,\t1,\t427000.0,\t1.0,\t138,\t0,\t0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JepbHZbAx8KD",
        "outputId": "9e82dd1a-68c5-47bc-835c-d9f0f99de1bc"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDErNpr1xM8U",
        "outputId": "62763703-b84d-4018-f713-a6d3933bb493"
      },
      "source": [
        "model(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0.]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp1RfAMgl6kk",
        "outputId": "d38629b3-01a0-47c1-e0de-347b3fd555fa"
      },
      "source": [
        "model.layer1.weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.2216, -0.0249, -0.1352,  0.0252,  0.2193, -0.1790,  0.2713,  0.0413,\n",
              "         -0.1346, -0.1240,  0.0103],\n",
              "        [-0.0094,  0.0311,  0.0688, -0.2302, -0.2204, -0.2733, -0.1166, -0.1306,\n",
              "          0.1314, -0.1471, -0.2015]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}